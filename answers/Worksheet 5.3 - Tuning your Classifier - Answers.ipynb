{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/GTK_Logo_Social Icon.jpg\" width=175 align=\"right\" />\n",
    "\n",
    "# Worksheet 5.3: Tuning your Classifier - Answers\n",
    "This worksheet covers concepts relating to tuning a classifier.  It should take no more than 20-30 minutes to complete.  Please raise your hand if you get stuck.  \n",
    "\n",
    "## Import the Libraries\n",
    "For this exercise, we will be using:\n",
    "* Pandas (http://pandas.pydata.org/pandas-docs/stable/)\n",
    "* Numpy (https://docs.scipy.org/doc/numpy/reference/)\n",
    "* Matplotlib (http://matplotlib.org/api/pyplot_api.html)\n",
    "* Scikit-learn (http://scikit-learn.org/stable/documentation.html)\n",
    "* YellowBrick (http://www.scikit-yb.org/en/latest/)\n",
    "* Seaborn (https://seaborn.pydata.org)\n",
    "* Lime (https://github.com/marcotcr/lime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:25:47.446960Z",
     "start_time": "2020-12-08T16:25:45.904801Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cgivre/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries - Make sure to run this cell!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import lime\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "For this exercise, we are going to focus on building a pipeline and then tuning the resultant model, so we're going to use a simpler model with only five features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:25:47.487560Z",
     "start_time": "2020-12-08T16:25:47.463398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>digits</th>\n",
       "      <th>entropy</th>\n",
       "      <th>vowel-cons</th>\n",
       "      <th>firstDigitIndex</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>1169.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2.641604</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1910.957011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3.235926</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1159.235043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3.026987</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1637.235431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3.664498</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0</td>\n",
       "      <td>818.281441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  digits   entropy  vowel-cons  firstDigitIndex       ngrams\n",
       "1128       8       0  3.000000    0.600000                0  1169.875000\n",
       "1730       9       0  2.641604    0.800000                0  1910.957011\n",
       "809       14       0  3.235926    0.166667                0  1159.235043\n",
       "1814      13       0  3.026987    1.166667                0  1637.235431\n",
       "93        14       0  3.664498    0.272727                0   818.281441"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.read_csv('../data/dga_features_final_df.csv')\n",
    "target = df_final['isDGA']\n",
    "feature_matrix = df_final.drop(['isDGA'], axis=1)\n",
    "feature_matrix.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing sets.\n",
    "We're going to need a training and testing dataset, so you know the drill, split the data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:25:49.092957Z",
     "start_time": "2020-12-08T16:25:49.087407Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simple Cross-Validation: Split the data set into training and test data\n",
    "feature_matrix_train, feature_matrix_test, target_train, target_test = train_test_split(feature_matrix, \n",
    "                                                                                        target, \n",
    "                                                                                        test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model\n",
    "For this exercise, we're going to create a K-NN Classifier for the DGA data and tune it, but first, create a classifier with the default options and calculate the accuracy score for it. (http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) \n",
    "\n",
    "The default parameters are shown below.\n",
    "```python \n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform')\n",
    "```           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:25:55.191788Z",
     "start_time": "2020-12-08T16:25:55.184152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here ...\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit( feature_matrix_train, target_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:25:58.088971Z",
     "start_time": "2020-12-08T16:25:58.066286Z"
    }
   },
   "outputs": [],
   "source": [
    "#Store the predictions\n",
    "default_predictions = clf.predict( feature_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:25:59.373291Z",
     "start_time": "2020-12-08T16:25:59.367591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score( target_test, default_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Performance \n",
    "Out of the box, the model achieves approximately 85% accuracy.  Better than chance but let's see if we can do better. \n",
    "\n",
    "**Note:  This notebook is written without using fixed random seeds, so you might get slightly different results.**\n",
    "\n",
    "### Scaling the Features\n",
    "K-NN is a distance-based classifier and hence it is necessary to scale the features prior to training the model.  For this exercise however, let's create a simple pipeline with two steps:\n",
    "\n",
    "1.  StandardScaler\n",
    "2.  Train the classifier\n",
    "\n",
    "Once you've done that, calculate the accuracy and see if it has improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:26:43.142221Z",
     "start_time": "2020-12-08T16:26:43.130727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('clf', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(feature_matrix_train, target_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:26:43.968236Z",
     "start_time": "2020-12-08T16:26:43.940679Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_predictions = pipeline.predict( feature_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:26:44.542753Z",
     "start_time": "2020-12-08T16:26:44.537725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.884"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score( target_test, pipeline_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the features did result in a small improvement: .85 accuracy to .88.  But let's see if we can't do even better.\n",
    "\n",
    "### Using RandomSearchCV and GridSearchCV to tune Hyperparameters\n",
    "Now that we've scaled the features and built a simple pipeline, let's try to tune the hyperparameters to see if we can improve the model performance.  Scikit-learn provides two methods for accomplishing this task: `RandomizedSearchCV` and `GridSearchCV`. \n",
    "\n",
    "\n",
    "* `GridSearchCV`:  GridSearch iterates through all possible combinations of tuning parameters to find the optimal combination. (http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "* `RandomizedSearchCV`:  RandomizedSearch interates through random combinations of paremeters to find the optimal combination.  While RandomizedSearch does not try every possible combination, is considerably faster than GridSearch and has been shown to get very close to the optimal combination in considerably less time.  (http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) \n",
    "\n",
    "You can see in the results below, that the model was able to achieve **91.9%** accuracy with RandomSearch!   \n",
    "```\n",
    "[INFO] randomized search took 0.85 seconds\n",
    "[INFO] grid search accuracy: 91.93%\n",
    "[INFO] randomized search best parameters: {'clf__weights': 'uniform', 'clf__p': 1, 'clf__n_neighbors': 27, 'clf__metric': 'euclidean', 'clf__leaf_size': 25, 'clf__algorithm': 'kd_tree'}\n",
    "```\n",
    "\n",
    "Both `RandomizedSearchCV` and `GridSearchCV` require you to provide a grid of parameters.  You will need to refer to the documentation for the classifier you are using to get a list of paramenters for that particular model.  Also since we will be using the pipeline, you have to format the parameters correctly.  The name of the variable must be preceeded by the name of the step in your pipeline and two underscores.  For example.  If the classifier in the pipeline is called `clf`, and you have a tuning parameter called `metric`, the parameter grid would be as follows:\n",
    "```python\n",
    "params = {\n",
    "    \"clf__n_neighbors\": np.arange(1, 50, 2),\n",
    "    \"clf__metric\": [\"euclidean\", \"cityblock\"] \n",
    "}\n",
    "```\n",
    "\n",
    "### Your Task\n",
    "Using either GridSearchCV or RandomizedSearchCV, improve the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:27:31.219020Z",
     "start_time": "2020-12-08T16:27:21.444006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] randomized search took 9.77 seconds\n",
      "[INFO] grid search accuracy: 91.40%\n",
      "[INFO] randomized search best parameters: {'clf__weights': 'uniform', 'clf__p': 2, 'clf__n_neighbors': 13, 'clf__metric': 'manhattan', 'clf__leaf_size': 45, 'clf__algorithm': 'ball_tree'}\n"
     ]
    }
   ],
   "source": [
    "params = {\"clf__n_neighbors\": np.arange(1, 50, 2), \n",
    "         \"clf__weights\": [\"uniform\", \"distance\"],\n",
    "         \"clf__algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "         \"clf__leaf_size\": np.arange(1, 80, 2),\n",
    "         \"clf__p\": [1,2],\n",
    "         \"clf__metric\": [\"euclidean\", \"manhattan\"]}\n",
    "\n",
    "\n",
    "\n",
    "grid = RandomizedSearchCV(pipeline, params, n_iter=100)\n",
    "start = time.time()\n",
    "grid.fit(feature_matrix_train, target_train)\n",
    " \n",
    "# evaluate the best randomized searched model on the testing\n",
    "# data\n",
    "print(\"[INFO] randomized search took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "#acc = grid.score(feature_matrix_test, target_test)\n",
    "acc = grid.best_score_\n",
    "print(\"[INFO] grid search accuracy: {:.2f}%\".format(acc * 100))\n",
    "print(\"[INFO] randomized search best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "Your final task is to:\n",
    "1.  Using RandomForest, create a classifier for the DGA dataset\n",
    "2.  Use either GridSearchCV or RandomizedSearchCV to find the optimal parameters for this model.\n",
    "\n",
    "How does this model compare with the first K-NN classifier for this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T14:32:50.727745Z",
     "start_time": "2020-07-30T14:32:40.605427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] randomized search took 10.12 seconds\n",
      "[INFO] grid search accuracy: 91.07%\n",
      "[INFO] randomized search best parameters: {'n_estimators': 151, 'max_features': 'log2', 'max_depth': 7, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "params = {\n",
    "    \"n_estimators\": np.arange(1, 400, 50),\n",
    "    \"max_features\": ['auto', 'sqrt','log2' ],\n",
    "    \"max_depth\": np.arange(1, 20, 2),\n",
    "    \"criterion\": ['gini','entropy']\n",
    "} \n",
    "\n",
    "rf_grid = RandomizedSearchCV(rf_clf, params )\n",
    "start = time.time()\n",
    "rf_grid.fit(feature_matrix_train, target_train)\n",
    " \n",
    "# evaluate the best randomized searched model on the testing\n",
    "# data\n",
    "print(\"[INFO] randomized search took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "#acc = grid.score(feature_matrix_test, target_test)\n",
    "acc = rf_grid.best_score_\n",
    "print(\"[INFO] grid search accuracy: {:.2f}%\".format(acc * 100))\n",
    "print(\"[INFO] randomized search best parameters: {}\".format(rf_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
