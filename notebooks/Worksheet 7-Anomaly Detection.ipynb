{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/GTK_Logo_Social Icon.jpg\" width=175 align=\"right\" />\n",
    "\n",
    "# Worksheet 7.0 Anomaly Detection\n",
    "\n",
    "This worksheet covers concepts relating to Anomaly Detection.  It should take no more than 20-30 minutes to complete.  Please raise your hand if you get stuck.  \n",
    "\n",
    "There are many ways to accomplish the tasks that you are presented with, however you will find that by using the techniques covered in class, the exercises should be relatively simple. \n",
    "\n",
    "## Import the Libraries\n",
    "For this exercise, we will be using:\n",
    "* Pandas (http://pandas.pydata.org/pandas-docs/stable/)\n",
    "* Numpy (https://docs.scipy.org/doc/numpy/reference/)\n",
    "* Matplotlib (http://matplotlib.org/api/pyplot_api.html)\n",
    "* PyFlux (https://pyflux.readthedocs.io/en/latest/)\n",
    "\n",
    "**Note:  At the time of writing, PyFlux can be difficult to install with Python 3.7.  This module can be run with either `PyFlux` or `StatsModels`** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T03:34:13.671160Z",
     "start_time": "2019-07-24T03:34:12.182536Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyflux as pf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "style.use(\"ggplot\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part One:  Finding Anomalies in CPU Usage Data\n",
    "The first part of this lab, you will be examining CPU usage data to find anomalies. \n",
    "\n",
    "## Step One:  Get the Data\n",
    "For this example, we will be looking at CPU Utilization Data to see if we can identify periods of unusual activity.  The data can be found in several files:\n",
    "\n",
    "* `cpu-full-a.csv`:  A full set of CPU usage data without anomalies\n",
    "* `cpu-train-a.csv`:  The training set from data set A\n",
    "* `cpu-test-b.csv`:  The test set from data set A\n",
    "* `cpu-full-b.csv`:  A full set of CPU usage data with an anomaly\n",
    "* `cpu-train-b.csv`:  The training set from data set A\n",
    "* `cpu-test-b.csv`:  The test set from data set A\n",
    "\n",
    "\n",
    "This dataset is from examples in *Machine Learning & Security*  by Clarence Chio and David Freeman.  https://github.com/oreilly-mlsec/book-resources/tree/master/chapter3/datasets/cpu-utilization.\n",
    "\n",
    "First let's take a look at the data set A.  For the first part of this lab, load the training dataset into a dataframe.  DataFrames have an option `infer_datatime_format` which, when set to `True`, will automatically infer dates. Setting this will save time and steps in data preparation. \n",
    "\n",
    "Once the data is loaded, call the usual series of exploratory functions and most importantly, plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T03:34:16.100390Z",
     "start_time": "2019-07-24T03:34:16.085678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Two:  Fit an ARIMA Model\n",
    "Since we are dealing with time series data, let's train an ARIMA model and see how well this technique fits the actual data. \n",
    "\n",
    "ARIMA has three parameters:\n",
    "\n",
    "* `p` (`ar`):  The number of lag observations included in the model\n",
    "* `d` (`integ`): The number of times the raw observations are differenced\n",
    "* `q` (`ma`):  The size of the moving average window\n",
    "\n",
    "For the ARIMA model, use 11 for both the `ar` and `ma` parameters, and 0 for the `integ` parameter. The `ARIMA` function in PyFlux has a series of functions \n",
    "\n",
    "PyFlux has a series of plotting functions to visualize the model's performance including:\n",
    "\n",
    "* `plot_fit()`:  This plot compares the fit of the ARIMA model with the actual data\n",
    "* `plot_predict_is()`: This plot compares the predictions with the data. \n",
    "* `plot_predict()`: This plot compares the predictions and the confidence of the predictions\n",
    "\n",
    "Run these all these plots on your model and see how well it forecasts the data.\n",
    "\n",
    "Full documentation available here: https://pyflux.readthedocs.io/en/latest/arima.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T04:17:18.963707Z",
     "start_time": "2019-07-24T04:14:37.792344Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Three:  Find Anomalies in the CPU data\n",
    "Using data set `B` train a new model. Once you have a trained model, the next step is to call the `.predict()` method to generate 60 predictions.  \n",
    "\n",
    "Next, compare the predictions with the actual values in the test set, similar to how we assess the accuracy of a classifier.  We will call the difference between the actual and predicted value the anomaly score.  Calculate the anomaly score for the test data.  Finally, plot the anomaly scores, and see if you can find the time intervals with the highest anomaly score. \n",
    "\n",
    "In \"real life\", if you were streaming this, the first instance of an anomaly score outside of a pre-determined threshold would cause an alert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T05:03:46.427827Z",
     "start_time": "2019-07-24T05:03:46.416428Z"
    }
   },
   "outputs": [],
   "source": [
    "df2_train = # Your code here... Use cpu-train-b.csv\n",
    "df2_test = # Your code here... Use cpu-test-b.csv\n",
    "\n",
    "# More code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "If all went well, you should see anomalous behavior at 10 seconds into the test data.  Remembering that the forecasting's confidence goes down over time, the first anomaly should be enough to throw an alert for investigation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
